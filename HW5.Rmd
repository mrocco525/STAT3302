---
title: "Assignment 5"
author: "Mason Rocco"
date: "2023-04-22"
output:
  pdf_document: default
  html_document: default
---


# Problem 1

### a)
$u_1 = \sum^n_1c_ix_i, A^tx$ such that $A^t = (c_1,...,c_n)$
$u_1\sim N_p(A^t\mu_i,A^t\Sigma{A})$

### b)
$U \sim N_2(A\mu, A^t\Sigma{A})$, where $A^t = (c_i,...,c_n,b_j,...,b_n)$ and $A^tx = U$

### c)
$u_1 \perp\!\!\! \perp u_2$ when $cov(u_1, u_2) = {0}$

# Problem 2 

### a) 
Since we know that $y = 3x_1 -2x_2+x_3$, we can also say that $a^tx = y$, where
$a = \begin{pmatrix}3 \\ -2 \\ 1 \end{pmatrix}$. Using this, we can find the
distribution of y as such:

$y\sim{N_3}(a^t\mu,a^t\Sigma{a})$

```{r}
mu <- c(2, -3, 1)
sigma <- matrix(c(1,1,1,1,3,2,1,2,2), nrow = 3, ncol = 3)
a <- c(3, -2, 1)

t(a) %*% mu
t(a) %*% sigma %*% a
```

Thus, the distribution of y is:
\
$y\sim{N_3}(13, 9)$

### b)
```{r}
a_1 <- 1
a_3 <- 1
A <- matrix(c(0, 1, 0, a_1, 1, a_3), nrow = 2, ncol = 3, byrow = T)
cov(A)
```

As can be seen above, setting $a = \begin{pmatrix}1 \\ 1 \end{pmatrix}$ makes
$z \perp\!\!\! \perp x_2$ true. This can be shown in the variance covariance
matrix, and since the values of $\sigma_{21} = \sigma_{12} = 0$, we see that
$z \perp\!\!\! \perp x_2$.


# Problem 3
```{r, include=FALSE}
library(readr)
library(ggplot2)
blood_glucose <- read_table("C:/Users/mrocc/Desktop/STAT 3302/Data/blood_glucose.txt")
```

```{r}
# PCA on S
pcaS <- prcomp(blood_glucose)
summary(pcaS)

# PCA on R
pcaR <- prcomp(blood_glucose, scale. = T)
summary(pcaR)
```

```{r}
var1 <- pcaS$sdev^2 / sum(pcaS$sdev^2)
qplot(c(1:6), var1) +
  geom_line() +
  xlab("Principal Component") +
  ylab("Variance Explained") +
  ggtitle("Scree Plot for S") +
  ylim(0,1)

var2 <- pcaR$sdev^2 / sum(pcaR$sdev^2)
qplot(c(1:6), var2) +
  geom_line() +
  xlab("Principal Component") +
  ylab("Variance Explained") +
  ggtitle("Scree Plot for R") +
  ylim(0,1)
```




Since we can see that using PCA on S requires only 5 PC variables to explain 95%
of the total variation, vs. needing 6 variables to reach the same amount using R,
this shows that using S is more appropriate in this situation. 

We also see this in the scree plot, which again shows that using the PCA on S
would be more appropriate in this situation.

